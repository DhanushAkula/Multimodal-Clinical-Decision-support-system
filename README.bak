# Multimodal Clinical Decision Support System

## Project Overview
Diagnostic errors account for **10–15% of adverse outcomes in healthcare**, often due to the separate analysis of medical images and clinical notes. This project proposes a **Clinical Decision Support (CDS) framework** that integrates **multimodal medical data** (images + clinical notes) with **biomedical knowledge graphs** to improve diagnostic reasoning and reduce errors.

Our approach combines **image embeddings (CLIP/ViT)**, **text embeddings (BioBERT)**, and a **biomedical knowledge graph** (UMLS, BioKG) to build a **Graph Neural Network (GNN)** for diagnostic ranking and case retrieval. The goal is to reduce diagnostic errors by **~30%** while providing interpretable, knowledge-driven reasoning support.

---

## Proposed Features
- **Multimodal Embeddings**  
  - Medical images encoded using CLIP/ViT.  
  - Clinical notes encoded using BioBERT.  

- **Knowledge Graph Construction**  
  - Built from biomedical ontologies (UMLS, BioKG).  
  - Entity linking for symptoms, diagnoses, and treatments.  

- **Graph Neural Network (GNN)**  
  - Learns from integrated embeddings + graph structure.  
  - Provides diagnostic ranking and case retrieval.  

- **Reproducible Pipelines**  
  - Orchestrated using **Apache Airflow**.  
  - Containerized with **Docker** for portability.  



## Authors
- **Satwik Reddy Sripathi** – sripathi.sa@northeastern.edu  
- **Dhanush Akula** – akula.d@northeastern.edu  
- **Avinash Arutla** – arutla.a@northeastern.edu  

